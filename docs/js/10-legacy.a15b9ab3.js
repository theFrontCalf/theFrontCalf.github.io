"use strict";(self["webpackChunkofficial"]=self["webpackChunkofficial"]||[]).push([[10],{2010:function(e,t,i){i.d(t,{Z:function(){return l},A:function(){return s}});var n={layout:{navList:{home:"Home Page",coreTechnology:"Technical Roadmap",productions:"Products and Applications",aboutus:"About Us",joinus:"Join Us",news:"News"},footer:{iconList:{addr:{label:"Business Adress：",value:["18th Floor, Block B, Sai’er Building, Tsinghua Science Park, Haidian District, Beijing, China","A2101, Hongqiao Vantone Center, No.333 Suhong Road, Minhang District, Shanghai"]},invest:{label:"Investment cooperation：",value:["invest@phigent.ai"]},bp:{label:"Business cooperation：",value:["bd@phigent.ai"]},other:{label:"Other cooperation：",value:["mkt@phigent.ai"]}},copyright:"© Beijing PhiGent Robotics Technology Co., Ltd ｜Beijing ICP prepared No.2022009455-1 "}},swiper:{banner:[{text:"Co-optimization of software and hardware<br>Build 3D intelligent computing for autonomous driving and robotics"}]},home:{subBanner:{banner:[{text:"PhiGent Robotics announced the completion of $30 million in the Series A funding to accelerate technological breakthroughs and large-scale mass production of next-generation autonomous driving.",subText:'On 2022 May 18, Beijing Phigent Technology Co., Ltd.  ("PhiGent Robotics") announced the completion of $30 million in the Series A funding.'},{text:"PhiGent News丨Strategic Cooperation between PhiGent Robotics & ZongMu<br>Technology, accelerates the process of vehicle intelligent transformation",subText:"As an important partner of ZongMu Technology in full-stack autonomous driving solutions, PhiGent will cooperate with ZongMu Technology, to define and promote the flagship full-stack autonomous driving product."},{text:"Good news! AMD-Xilinx Global Adaptive Computing Challenge Second Place: <br>PhiGent Robot Binocular Vision LiDAR Solution",subText:"With its self-developed PhiGent Heimdallr binocular vision LiDAR solution, PhiGent stood out from 1,600 participating teams around the world and won the second prize in the Edge Computing track."}]},inNumbers:{title:"In Numbers",numbersList:[{title:"200+",subTitle:"Perception Elements"},{title:"500M+",subTitle:"Peception Distance"},{title:"100x",subTitle:"Improved Efficiency of Data Utilization"}]},cardList:[{title:"Autonomous Driving Solution",desc:"We provide customers with three products and solutions covering perception, planning and control, and data-driven closed-loop tool chains, with specific functions covering solutions such as L2 assisted driving (i- ACC, LKS, etc.) and L2++ (NOP, APA, AVP, etc.) for full-scene higher-order assisted driving."},{title:"Vision-LiDAR",desc:"PhiGent ViDAR products build a dense space point-cloud iof vehicle front driving area in real time, support the accurate detection and positioning of various traffic participants and road elements, improve the vehicle perception of intelligent driving and the understanding of the three-dimensional world."}],aboutusIntro:{title:"Co-optimization of software and hardware<br>Build 3D intelligent computing for autonomous driving and robotics",desc:"PhiGent has profound experience in AI perception algorithms, planning control, infrastructure 2.0 of software, and the large-scale practice of data-driven. PhiGent focuses on next-generation autonomous driving technology and product development. PhiGent will work with industry partners to accelerate the promotion and implementation of autonomous driving through the full-process data-driven autonomous driving brain with 3D understanding."},cooperationList:[{title:"Strategic Partners",desc:"Cooperate with leading companies in the automotive and autonomous driving industry to promote technological innovation and commercialization of automotive intelligence."},{title:"Financing Cooperation Partners",desc:"Get investment from top venture capital institutions and industry leaders."}]},news:{banner:{date:"2022/05/18",title:"PhiGent Robotics announced the completion of $30 million in the Series A funding to accelerate technological breakthroughs and large-scal...",subtitle:"PhiGent Robotics announced the completion of $30 million in the Series A funding to accelerate technological breakthroughs and large-scale ma...",id:"consulte_14",type:"consulte"},tabsList:{allNews:"All News",consulte:"Company News",cooperation:"Ecological Cooperation",technical:"Products Technology",activity:"Company Acitity"},newsDetail:"News Detail"},aboutus:{banner:{text:"Co-optimization of software and hardware<br>Build 3D intelligent computing for autonomous driving and robotics"},intro:{title:"Company Profile",content1:"PhiGent Robotics was established in August 2021, focusing on the research and development of next-generation autonomous driving solutions centered on visual 3D understanding. As one of the earliest domestic leaders in the deep cultivation of artificial intelligence algorithms, software and chips, the founding team of PhiGent Robotics has many years of cooperation foundation, successful entrepreneurial experience and rich commercial implementation experience. ",content2:"PhiGent Robotics continues to focus on the vision of “Co-optimization of software and hardware, build 3D intelligent computing for autonomous driving and robotics, and realise the intelligent interaction between machines and the physical world”, to solve key fundamental problems of autonomous driving and robotics with innovative technological breakthroughs. Besides, with autonomous driving products and business models that can be mass-produced, PhiGent Robotics continues to provide high-performance, cost-effective, and highly reliable solutions and product services for OEMs and Tier 1 suppliers."},team:{title:"Core Team",teamList:[{personalProfile:{name:"Du Dalong",position:"Co-Founder",position_en:"Co-Founder"},profileDetail:["Former head of research and development of an AI technology company, former director of Horizon Algorithms, former architect of Baidu Research Institute;","PhD in Innovation Leading Engineering, Tsinghua University, Master of Institute of Computing Technology, Chinese Academy of Sciences;","R&D and scale implementation of the first domestic AI chip product solution;","R&D and scale implementation of AI2B software and hardware products for smart cities;",'Two consecutive times won the highest honor of Baidu Engineer-"Baidu Million Dollars Top Award": PaddlePaddle, large-scale image search landing;',"Lead the team to achieve world-class results in AI competitions such as MSCOCO and FRVT"]},{personalProfile:{name:"Liu Jingxiu",position:"Partner, VP of Marketing and Business Development",position_en:"Partner, VP of Marketing and Business Development"},profileDetail:["Former head of research and development of an AI technology company, former director of Horizon Algorithms, former architect of Baidu Research Institute;","PhD in Innovation Leading Engineering, Tsinghua University, Master of Institute of Computing Technology, Chinese Academy of Sciences;","R&D and scale implementation of the first domestic AI chip product solution;","R&D and scale implementation of AI2B software and hardware products for smart cities;",'Two consecutive times won the highest honor of Baidu Engineer-"Baidu Million Dollars Top Award": PaddlePaddle, large-scale image search landing;',"Lead the team to achieve world-class results in AI competitions such as MSCOCO and FRVT"]}]},abilityList:{algorithm:"Algorithm",control:"Planning & Control",power:"Computing",application:"Software",Hardware:"Hardware",production:"Product",business:"business&development",intro:"PhiGent has achieved a full-stack development team with more than 100 people whose background covers algorithms, plannig & control, computing, software, hardware, products, and business in Beijing, Shanghai and Suzhou. The team has strong capabilities to contribute and deliver full-stack mass-production product/solutions.<br>The core team members are all from the world's top AI algorithms, AI chips and autonomous driving companies, and they have gathered the earliest domestic experts in the development of artificial intelligence algorithms, AI chips and the implementation of autopilot products."},history:{title:"development Progress",content:{2022:[{month:"March",desc:"Launched the premium version of  Advanced Driving Assistance System (ADAS) solution with the tech core of BEV 3D understanding."},{month:"January",desc:"Reached several in-depth cooperation intentions with multiple OEMs/Tier1."},{month:"January",desc:"Won ‘Synced Machine Intelligence Awards’ and 'AI China'."},{month:"January",desc:"PhiGent's intelligent driving solution is on the road in real vehicles (realizing i-ACC/LKS/Pilot/NOP/ALC/PJA (urban intersection)/P-CAS, etc.)."},{month:"January",desc:"Realize an integrated team of 100 people."}],2021:[{month:"December",desc:"Launched PhiGent Heimdallr —— the first binocular vision LiDAR product."},{month:"November",desc:"Cooperate with a Tier1 to jointly serve the night vision ADAS mass production project of the OEM."},{month:"November",desc:"PhiGent Shanghai and Suzhou companies were established."},{month:"November",desc:"BEVDet, a new paradigm of 3D perception, won the world's first in the autopilot authoritative evaluation (nuScenes)."},{month:"October",desc:"Completed millions of dollars in Angel rounds and Pre-A rounds of financing."},{month:"August",desc:"Beijing Phigent Robotics Technology Co., Ltd. (Phigent) was established."}]}}},joinus:{banner:{title:"The future of PhiGent is because of you",btns:{socialRecruit:"Social Recruiting",campusRecruit:"Campus Recruiting"}},subBanner:{title:"Join Us",banner:[{title:"Here,,",desc:"you can participate in building the next generation of autopilot solutions and leading the trend."},{title:"Here,,",desc:"you can stick to long-termism and be brave to be yourself."},{title:"Here,,",desc:"you can use your skill to provide convenience to hundreds of millions of people."}]},teamIntro:{title:"team introduction",parts:[{title:"Algorithm Team",desc:'<span style="font-weight: 700; color: #202020;">The algorithm team has world-class AI and robot algorithm full-stack R&D capabilities. The core team is the first to engage in the R&D and application of deep learning in China and has won many international authoritative artificial intelligence and autonomous driving competitions such as MSCOCO, FRVT, nuScenes, and KITTI. The published world-class datasets have been applied for and widely used by hundreds of research institutions, and team members have published dozens of top academic papers. At the same time, the team has profound experience in software and hardware collaborative optimization and extensive practical experience in application implementation, which supports the large-scale business implementation of multiple application scenarios.</span><br/><br/>\n        At present, the team has systematic and long-term planning in 2D/3D vision perception and reconstruction, scene and behavior prediction, decision planning & control, ISP and other aspects for binocular & multi-vision computing, high-level autonomous driving solutions and other businesses application aspects. At the same time, there is also deep practice and systematic planning on the infrastructure using the algorithm.'},{title:"Planning & Control Team",desc:"<span style=\"font-weight: 700; color: #202020;\">The planning & control team is mainly responsible for multi-sensor environment modeling, decision planning and control. The company's 3D vision real-time perception is used to complete the self-developed multi-sensor data fusion, and the complete real-time visual-SLAM system solution can be completely realized without relying on HD-Map. The 'Safety-First' model can be used to complete a decision-making planning system with parallel rules and strengthen-learning redundancy. At the same time, the limited resources of SOC and the advantages of high functional safety of MCU can be used to improve the accuracy of control functions and the ability to generalize scenarios.</span><br/><br/>\n        The core members of the team are from world-class OEMs and autonomous driving companies, with rich industry experience and innovative spirit. The team has deep understanding of the interaction and conflict mechanisms between drivers, driving behaviors and machine intelligent control systems, and then establishes a human-machine collaborative driving system and an autonomous driving regulation and control system to solve key issues in the development of autonomous driving and ensure landing in various practical scenarios."},{title:"Computing Team",desc:'<span style="font-weight: 700; color: #202020;">The computing team has the capabilities of integrated design, simulation and verification. The core members are from international and domestic leading autonomous driving and graphics chip technology companies, with years of experience in FPGA development, including industry-leading deep learning processors and machine vision systems. They have profound experience in the design and implementation of AI accelerators and image signal processors.</span><br/><br/>\n        The team has developed products such as vision LiDAR and vision inertial odometer based on vehicle-grade XAZU5EV devices. In the future, the team has formulated long-term system plans in the directions of 3D stereo vision, AI ISP, SLAM, and multi-sensor fusion computing. The goal is to provide a high-performance computing platform for computing tasks such as sensor fusion, perception, prediction, and planning & control. Close cooperation with the cutting-edge 3D vision perception algorithm team to provide industry-leading FPGA implementation solutions, as well as graphics and image processing IP and computing IP that comply with automotive regulations.'},{title:"Software Team",desc:'<span style="font-weight: 700; color: #202020;">The software team has been deeply involved in engineering for more than ten years, and has profound experience in AI engineering and implementation. The core team is the first to use GPU for large-scale deep learning training in China, and it is also the first pioneer in China to transplant and deploy CV algorithms on mobile terminals and achieve real-time effects. The core team is the first in the industry to propose an AI software construction framework based on data flow graphs. With the continuous evolution of this framework, large-scale AI projects have been implemented on multiple mainstream heterogeneous computing platforms.</span><br/><br/>\n        Currently, the team covers the research and development of full-stack software for autonomous driving, and has a long-term roadmap in BSP, underlying framework, middleware, and applications. The goal is to build the safest, most stable, and most efficient software system in the autonomous driving industry while supporting reliable and fast landing AI ISP, binocular/multi-eye stereo vision and high-level autopilot solutions.'},{title:"Hardware Team",desc:'<span style="font-weight: 700; color: #202020;">The hardware team comes from the top-tier autonomous driving solution and chip company, and has rich experience in autonomous driving related development. Since 2015, it has focused on software and hardware collaboration in artificial intelligence vision, and the image and hardware acceleration capabilities have fully realized independent intellectual property rights. The team has successfully launched a series of pre-sensing platform products based on FPGA chips, and sold well in Robotaxi and international Tier1 companies. The core members have participated in the development of the earliest AI chips and  automotive AI chips in China, as well as the development of autonomous driving image modules and domain control.</span><br/><br/>\n        Currently, the hardware team is responsible for platform product development and self-development of the hardware platform for autonomous driving solutions, including binocular vision LiDAR hardware products that strengthen the core capabilities of PhiGent’s forward perception of autopilot, image ISPs related to autopilot, and a series of AI accelerators chip platforms, such as Orin, Qualcomm, Horizon\'s J chips and other high-level autopilot solution platforms.'}]},talentConcept:{title:"Concept of Talent",parts:[{title:"open"},{title:"innovative"},{title:"focus"},{title:"motivated"}]},welfare:{title:"team introduction",items:[{title:"Generous year-end bonuses and early rise options"},{title:"Full social insurance, \n        provident fund and \n        supplementary medical insurance"},{title:"10 days of annual leave, \n        maternity leave, paternity leave and \n        other leave benefits"},{title:"Fancy fruits and snacks for\n        afternoon tea"},{title:"Various clubs and\n        fitness activities"},{title:"Ergonomic seat for \n        your efficiency and comfort"}]}},visualRadar:{banner:{text:"Vision-Lidar——<br>\n      Forward Visual Perception for<br>\n      Advanced Intelligent Driving",subText:"PhiGent Heimdallr is a 4D vision sensor developed for advanced intelligent driving systems. <br>\n      Dense depth point-cloud, pixel-level aligned RGB data, and high frame rate can support the target<br>detection algorithm, detect and identify various dynamic and static road targets earlier.<br>\n      The supporting multi-type perception algorithm IP and one-stop intelligent driving packaging<br>scheme can further reduce the application cycle and threshold for customers."},dallr:{parts:[{text:"2MP/8MP resolution"},{text:"60°/100°/120° horizontal<br>field of view"},{text:"30FPS frame rate"},{text:"RGB+Depth sync output"},{text:"Optionally equipped with self-developed perception algorithm IP"},{text:"Computing platform specified by clients"}],content:[{label:"Optionally equipped with PhiGent Robotics self-developed perception algorithm IP",text:"The self-developed perception algorithm IP mainly refers to all types of target detection algorithms, lane line detection algorithms, traffic sign recognition, road elevation detection, road type recognition, etc. developed by PhiGent Robotics based on PhiGent Heimdallr data. Clients can choose the corresponding algorithm IP according to the requirements for application. The corresponding computing occupation and adaptation period need to be determined based on specific project communication."},{label:"Computing platform specified by clients",text:"When the clients specifies the computing platform, PhiGent Robotics deploys software modules such as image preprocessing, stereo matching, self-calibration, and perception algorithm IP (if selected) on the clients' computing platform. The specific computing power occupation and system solution design need to be determined in conjunction with specific project communication."}]},cardItems:[{title:"Pixel-level depth vision sensor",text:"PhiGent Heimdallr outputs more than 10 million depth point clouds per second. The dense point cloud output can support target detection algorithms and more accurately detect small target objects such as distant pedestrians, ice cream buckets, and warning triangles.",subText:{label:"Pixel-level depth vision sensor",text:"Resolution equivalent to the input image to the matching module. All current PhiGent Heimdallr products have a depth-height resolution greater than 720P."}},{title:"Better scene generalization",text:"PhiGent Heimdallr is equipped with a deep learning stereo matching algorithm developed by PhiGent. While retaining high-precision ranging capabilities, it can also accurately match depth point clouds for targets with weak textures* and repetitive textures (such as solid-color box trucks, road fences, etc.). It is guaranteed that the perception system still has robust detection capabilities in extreme traffic scenarios such as traffic accident sites and construction sections.",subText:{label:"weak textures",text:"The object to be tested is visually distinct in color and texture from the road surface, excluding completely transparent or specularly reflective objects."}},{title:"All types of object detection with pure vision",text:"A single sensor can output pixel-level aligned depth point clouds and RGB images, and with deep learning recognition and 3D point cloud clustering target detection algorithms, to obtain any pieces of information including vehicles, pedestrians, road signs, traffic facilities, road debris and cartons. The information about the target object improves the detection ability of the front visual perception system."},{title:"Online self-calibration ensures consistent performance",text:"PhiGent Heimdallr is standard configured with an online self-calibration system to ensure that the product can maintain the original ranging performance and reduce the risk of system failure and after-sales costs after being subjected to temperature, vibration, and component aging."},{title:"Car-grade stereo camera",text:"Full-stack design and development, the products meet the general standard requirements such as GB/T28046, GB/T21437, GB/T18655, ISO7637.3, GB/T 17626.4, etc., and more than ten specific reliability tests have been added for the characteristics of the vehicle environment to ensure that the products can be mass-produced and remain strong stability."},{title:"Full stack intelligent driving solution + Supporting tool chain accelerates mass production",text:"PhiGent Robotics can provide a complete set of intelligent driving solutions and supporting toolchains which include PhiGent Heimdallr to ensure customers retain the control of the definition system while effectively reducing the cycle and cost of customers' independent development and adaptation.",btnText:"Understanding the PSD System"}],productions:{title:"Applications",parts:[{text:"Forward sensing of autonomous driving system"},{text:"Half / Full Active Smart Suspension"},{text:"Intelligent driving function downgrade redundancy"},{text:"Passability Testing"}]},bottomVideo:{title:"Splendid moment of PhiGent Heimdallr"}},autoDriving:{banner:{text:"Autonomous Driving Solution",subText:"With visual 3D understanding as the core, PhiGent will create an end-to-end data-driven<br>autopilot solution based on the software 2.0 architecture,to realize the perception and<br>understanding of the autopilot vehicle environment in a multi-dimensional space, and work<br>with industry partners to promote the development as well as innovation of autopilot,<br>redefine future mobility."},solution:{subText:"Adopt a pre-fusion end-to-end optimization solution based on vision and compatible with sensors such as Radar and<br>Lidar, and provide full-stack products from the sensor layer, perception layer, and regulatory control application layer.",parts:[{text:"Low hash rate requirement"},{text:"Strong Ego-Car Intelligence "},{text:"Full stack algorithm capability"},{text:"Continuously iterable"},{text:"Customised experience"}]},coreSolution:{title:"Main Schemes",subTitle:"Vision-based flexible sensor configuration",desc:"With an open software and hardware framework, it can adapt to different vehicle<br>heterogeneous computing platforms and different sensor architectures, fully consider the dual<br>needs of customers for cost-effectivity and reliability, and meet the functional experience<br>requirements of different scenarios.",details:[{title:"Visual Perception",desc:"Configuration and customization can be made according to customer platform requirements to meet the needs of product functions at different levels and coverage of different scenarios of autopilot under this camera configuration. "},{title:"Millimeter-wave radar",desc:"The amount of millimeter-wave radar can be reduced according to the actual plan configuration."},{title:"Other compatible sensors",desc:""}]},projectBox:{title:"Multi-sensor fusion algorithm and mass production engineering capability",subTitle:"Extensive experience in mass production engineering on adapting multi-sensor fusion.<br>Based on efficient fusion algorithms, we deliver high-quality smart driving functions to<br>achieve multi-scene coverage of functions and experience enhancement."},toolChain:{title:"A complete tool chain",tools:[{label:"Data closed-loop platform",content:"The data acquisition system pre-algorithm adds a data closed-loop platform, which significantly shorten the implementation cycle of intelligent driving and reduce costs."},{label:"4D Data Labeling Platform",content:"The global point cloud with accurate 3D object shape and color, which is used to support 4D annotation is reconstructed based on visual radar. The annotation efficiency can be improved hundreds of times, greatly reducing the cycle and cost of intelligent driving."},{label:"In-vehicle visualization HMI tools",content:"Humanized HMI design can meet the needs of users with different roles."}]},scene:{title:"rich scenarios",desc:"Powerful perception algorithms and engineering capabilities for mass production verification meet the needs of flexible<br>combinations of computing platforms and sensors, creating rich intelligent driving scenarios.<br>The full-stack software and hardware technical capabilities of L4 level autopilot can provide dimensionality-reduced<br>intelligent driving solutions in combination with customers' vehicle models and scenario planning, and at the same time<br>reserve the ability to upgrade to high-end autopilot at low cost.",cardList:[{title:"Active security",desc:"The mass-production-proven full-speed active safety system, with two triggers by mistake for 100,000 kilometers, delivers high-quality urban safety experience."},{title:"High-speed pilot",desc:"It supports autonomous on and off ramps, optimal lane selection, automatic identification and adjustment of speed limits, and adaptive adjustment of driving strategies."},{title:"Urban pilot",desc:"It supports traffic light intersections and roundabouts in complex cities, narrow roads in urban villages, and non-mixed flow of human-machine driving."},{title:"Point- to- point",desc:"Combine local real-time road mapping with navigation maps, to support point-to-point customization in any scene, and continuous optimization of data-driven."}]},bottomVideo:{title:"Splendid moments of autopilot solutions product"}},technology:{doubleCore:{title:"Dual Core Drive",parts:[{title:'Build spatial intelligence based on <span style="color: #E50011">3D understanding</span> to achieve precise interaction between machines and the physical world',desc:"End-to-end data-driven, real-time 3D environment reconstruction modeling, understanding of the details of 3D space, and solving key core problems such as visual radar, 4D perception, and real-time mapping in autopilot solutions."},{title:'<span style="color: #E50011">Vehicle intelligence</span> covers all scenarios, application modules are flexible and customizable',desc:"Without relying on infrastructure (V2X, HD-Map), it achieves a fine and silky autopilot experience across scenarios with its superior vehicle perception and decision-making capabilities. Flexible modular product solutions as well as customizable user driving and interactive experience, help the new model of paid subscription for software services."}]},bevdet:{title:"BEVDet——<br>A New Paradigm of 3D Perception for Autopilot",desc:'<span style="font-weight: 700; color: #202020;">We proposed BEVDet, a new paradigm of 3D perception for a purely visual autopilot on<br>nuScenes, an authoritative evaluation set for autopilot, and achieved the world\'s first<br>(2021) result in purely visual 3D object detection.</span><br>\n      An autopilot perception framework that is based on visual radar ideas and builds eye-brain<br>synergy, restores the three-dimensional structure of the entire space through the vision-based<br>sensing system, and directly perceives and understands the three-dimensional space.<br>\n      From BEVDet to BEVDet4D, PhiGent continues to lead the development of<br>a new paradigm of autopilot BEV perception.',chartParts:[{title:"BEVDet"},{title:"BEVDet4D"}],cardList:[{title:"high performance",desc:"BEVDet has better generalization performance and less data requirement than Transformer for image-to-bev projection, which can significantly reduce the need for data volume."},{title:"Extensibility",desc:"The BEVDet framework is highly extensible. In future, PhiGent Robot will be expanded based on BEVDet to further realize the key core modules of pure autopilot such as visual radar, 4D perception, real-time local map, etc., and also provide an excellent new framework for multi-sensor pre-fusion."},{title:"Practicality",desc:"BEVDet achieves the same or better algorithm effect through lower hash rate requirements, which can greatly improve the hash rate utilization efficiency of the actual autopilot system."}],part3D:{title:"BEVDet 3D Perceived technical indicators",videos:[{title:"NuSense BEVDet 3D Perception",desc:"The effect of BEVDet on the nuSenses dataset"},{title:"6V all-around view, Vehicle Deployment",desc:"High-level autopilot real vehicle perception effect based on BEVDet (2022/3)"}]}},control:{title:"With the world's leading level of planning and control capabilities",desc:"Traditional rules and reinforcement learning are redundant and parallel, the modeling ability of<br>the safe and optimal environmental model, combined with the perceptual input of the three-dimensional<br>world to achieve accurate prediction, and complete the algorithm design of<br>optimal safety and traffic trajectory.<br>\n      The shadow system of automated data collection fulfills the end-to-end 4D perception<br>requirements based on BEV, and creates a dual-redundancy, full-scene generalized regulation<br>and control system."},computeSolution:{title:"High-Performance Adaptive Computing Solutions",desc:"PhiGnet has formulated long-term system planning in the directions of 3D stereo vision, AI ISP,<br>SLAM and multi-sensor fusion computing.<br>\n      The goal is to provide a high-performance computing platform for computing tasks such as<br>sensor fusion, perception, prediction, and planning and control. Provide industry-leading FPGA<br>implementation solutions, as well as graphics and image processing IP and computing IP that<br>meet automotive regulations."}},commen:{more:"Learn More",aboutus:"About us",showMore:"显示更多",noMore:"没有更多了～",backHome:"返回首页",navList:{home:"Home Page",coreTechnology:"Technical Roadmap",productions:"Products and Applications",aboutus:"About Us",joinus:"Join Us",news:"News",autoDriving:"autopilot solutions product",visualRadar:"Vision-LiDAR",companyInfo:"Company Profile",history:"development path"}}},o={layout:{navList:{home:"首页",coreTechnology:"核心技术",productions:"产品应用",aboutus:"关于我们",joinus:"加入我们",news:"新闻中心"},footer:{iconList:{addr:{label:"办公地址：",value:["北京市海淀区清华科技园赛尔大厦B座18层","上海市闵行区苏虹路333号虹桥万通中心 A2101"]},invest:{label:"投资合作：",value:["invest@phigent.ai"]},bp:{label:"业务合作：",value:["bd@phigent.ai"]},other:{label:"其他合作：",value:["mkt@phigent.ai"]}},copyright:"京ICP备2022009455号-1 北京鉴智机器人科技有限公司 © PhiGent Robotics, 2022 All rights reserved."}},swiper:{banner:[{text:"基于软硬件协同优化<br>构建自动驾驶与机器人的3D智能计算"}]},home:{subBanner:{banner:[{text:"鉴智机器人宣布完成3000万美元A轮融资，<br>加速下一代自动驾驶的技术突破和规模化量产落地",subText:"2022年5月18日，北京鉴智科技有限公司（“鉴智机器人”PhiGent Robotics）宣布完成3000万美元A轮融资。"},{text:"PhiGent News丨鉴智机器人与纵目科技达成战略合作，<br/>加速整车智能化变革进程",subText:"作为纵目科技在自动驾驶领航全栈方案端的重要伙伴，鉴智机器人将与纵目科技优势协同，共同打造高阶智驾全栈方案的标杆。"},{text:"喜讯！AMD-Xilinx全球自适应计算挑战赛二等奖：<br/>鉴智机器人双目视觉雷达方案",subText:"鉴智机器人凭借自主研发的PhiGent Heimdallr双目视觉雷达方案，从全球1600支参赛队伍脱颖而出，获得边缘计算赛道(Edge Computing)二等奖的成绩。"}]},inNumbers:{title:"关键数据",numbersList:[{title:"200+",subTitle:"感知元素"},{title:"500M+",subTitle:"感知距离"},{title:"100x",subTitle:"数据利用效率提升"}]},cardList:[{title:"自动驾驶解决方案",desc:"为客户涵盖感知、规划控制和数据驱动的闭环工具链等三方面产品及解决方案，具体功能覆盖了L2辅助驾驶（i- ACC，LKS等）以及L2++（NOP、APA、AVP等）的全场景高阶辅助驾驶等方案。"},{title:"视觉雷达",desc:"实时构建车辆行驶前方稠密空间点云，支撑精确检测和定位各类交通参与者和道路元素，提升智能驾驶的车辆感知和三维世界的理解能力。"}],aboutusIntro:{title:"基于软硬件协同优化，<br>构建自动驾驶与机器人的3D智能计算",desc:"鉴智机器人在AI感知算法、规划控制、软件2.0的基础设施、数据驱动的大规模实践上拥有丰富的经验，<br>专注于下一代自动驾驶技术与产品研发。将以3D理解为核心，通过全流程数据驱动的自动驾驶大脑，<br>与行业合作伙伴一起加速自动驾驶的推广与落地。"},cooperationList:[{title:"战略合作伙伴",desc:"与汽车工业及自动驾驶行业的领军企业合作，携手推进汽车智能化的技术革新与商业化落地。 "},{title:"融资合作机构",desc:"获得顶级风投机构及产业领军企业的投资，共同创造价值。"}]},news:{banner:{date:"2022/05/18",title:"鉴智机器人宣布完成3000万美元A轮融资，加速下一代自动驾驶的技术突破和规模化量产落地",subtitle:"2022年5月18日，北京鉴智科技有限公司（“鉴智机器人”PhiGent Robotics）宣布完成3000万美元A轮融资。",id:"consulte_14",type:"consulte"},tabsList:{allNews:"全部新闻",consulte:"企业资讯",cooperation:"生态合作",technical:"产品技术",activity:"公司活动"},newsDetail:"新闻详情"},aboutus:{banner:{text:"基于软硬件协同优化<br>构建自动驾驶与机器人的3D智能计算"},intro:{title:"公司简介",content1:"鉴智机器人成立于2021年8月，专注于以视觉3D理解为核心的下一代自动驾驶方案的研发。作为国内最早一批深耕人工智能算法、软件和芯片的领军者，鉴智机器人的创始团队有多年的合作基础，具备成功的创业经历和丰富的商业落地经验。",content2:"公司持续围绕“基于软硬件协同优化，构建自动驾驶与机器人的3D智能计算，实现机器与物理世界的智能化交互”的愿景，以创新的技术突破解决自动驾驶与机器人的关键基础性问题，并以可规模化量产的自动驾驶产品与业务模式，为主机厂和一级供应商提供高性能、高性价比、高可靠性的解决方案和产品服务。"},team:{title:"核心团队",teamList:[{personalProfile:{name:"都大龙",position:"联合创始人",position_en:"Co-Founder"},profileDetail:["原芯翌科技研发VP，前地平线算法总监，前百度研究院架构师；","清华大学创新领军工程博士，中科院计算所硕士；","国内首款AI芯片产品方案的研发与规模落地；","智慧城市AI2B软硬件产品的研发与规模落地；","连续两次获得百度工程师最高荣誉-“百度百万美金最高奖”：PaddlePaddle、大规模图搜落地；","带领团队在MSCOCO、FRVT等AI比赛中获得世界一流成绩"]},{personalProfile:{name:"刘竞秀",position:"合伙人，商务副总裁",position_en:"Partner, VP of Marketing and Business Development"},profileDetail:["前赛灵思AI全球市场总监，负责汽车、医疗、数据中心等行业的市场拓展，累计全产品周期收入过亿美金，在赛灵思期间面向全球头部车厂和主流零部件商提供基于FPGA的AI加速方案；","前深鉴科技商务VP，全面负责公司商务战略制定及落地，支撑公司以数亿美金全资被赛灵思收购；","前诺基亚大中华区商务总监，十余年通信行业市场拓展及产业链整合经验；","清华大学电子工程系学士、硕士，清华大学经管学院工商管理硕士；","拥有数十项国内外授权专利及数篇国际论文"]}]},abilityList:{algorithm:"算法",control:"规控",power:"计算",application:"软件",Hardware:"硬件",production:"产品",business:"商务",intro:"鉴智机器人已经在北京、上海、苏州实现覆盖算法、规控、计算、软件、硬件、产品、商务等百余人全栈团队，具备完整交付和量产的能力。<br/>核心团队成员均来自世界各大顶尖AI算法、AI芯片与自动驾驶公司，聚集了国内最早一批开展人工智能算法与AI芯片研发及自动驾驶产品落地的专家。"},history:{title:"发展历程",content:{2022:[{month:"3月",desc:"推出以BEV 3D理解为核心的高阶自动辅助驾驶方案"},{month:"1月",desc:"实现百人规模的完整团队。"},{month:"1月",desc:"鉴智智能驾驶方案实车上路(实现 i-ACC/LKS/Pilot/NOP/ALC/PJA（城市路口）/P-CAS等)"},{month:"1月",desc:"荣获“机器之心”「AI中国」两项大奖。"},{month:"1月",desc:"与多家主机厂/Tier1达成多项深度合作意向。"}],2021:[{month:"12月",desc:"推出PhiGent Heimdallr——首款双目视觉雷达产品。"},{month:"11月",desc:"与某Tier1合作共同服务主机厂夜视ADAS量产项目。"},{month:"11月",desc:"鉴智机器人上海、苏州公司成立。"},{month:"11月",desc:"3D感知新范式BEVDet获自动驾驶权威测评（nuScenes）世界第一"},{month:"10月",desc:"完成数千万美元天使轮与Pre-A轮融资。"},{month:"8月",desc:"北京鉴智机器人科技有限公司正式成立。"}]}}},joinus:{banner:{title:"鉴智未来，为你而来",btns:{socialRecruit:"社会招聘",campusRecruit:"校园招聘"}},subBanner:{title:"加入鉴智",banner:[{title:"在这里,",desc:"你可以参与构建下一代自动驾驶解决方案，引领时代潮流。"},{title:"在这里,",desc:"你可以坚持长期主义，勇敢做自己。"},{title:"在这里,",desc:"你可以用自己的技术，为亿万人提供生活便利。"}]},teamIntro:{title:"团队介绍",parts:[{title:"算法团队",desc:'<span style="font-weight: 700; color: #202020;">算法团队拥有国际一流的AI和机器人算法全栈研发能力，核心团队于国内最早从事深度学习相关的研发和应用，多次获得MSCOCO、FRVT、nuScenes、KITTI等国际权威人工智能和自动驾驶比赛冠军，发布的世界级数据集被数百家研究机构申请和广泛使用，团队成员发表顶级学术论文数十篇。同时，团队拥有丰富的软硬件协同优化经验和广泛的应用落地实践经验，支撑了多个应用场景的大规模业务落地。</span><br/><br/>\n        目前，团队在2D/3D视觉感知和重建、场景和行为预测、决策规划控制、ISP等方向上都有系统和长期的规划，用于双目&多目视觉计算、高级别自动驾驶方案等业务应用方向；同时在围绕算法的基础设施上也有深入的实践和系统的规划。'},{title:"规控团队",desc:'<span style="font-weight: 700; color: #202020;">规控团队主要负责自动驾驶中多传感器的环境建模、决策规划和控制。利用本公司3D视觉实时感知完成自研多传感器数据融合，可不依赖高精地图完全实现整套实时的视觉SLAM系统方案。可使用安全最优的数字模型完成规则与学习冗余并行的决策规划系统，同时利用SOC的有限资源与MCU的高功能安全的优势大幅度提升控制功能的准确性和场景泛化能力。</span><br/><br/>\n        团队主要成员来自世界一流的车企、自动驾驶公司，具备深厚的行业经验和创新精神。团队深入理解驾驶员、驾驶行为和机器智能控制系统之间的交互机制和冲突机理，进而建立人机协同共驾系统、自动驾驶规控系统，以解决自动驾驶发展路径中的关键问题，确保在各种实际场景中的落地。'},{title:"计算团队",desc:'<span style="font-weight: 700; color: #202020;">计算团队具备完整的设计、仿真和验证能力，核心成员均来自国际和国内领先的自动驾驶和图形图像芯片技术公司，具备多年FPGA开发经验，包括业界领先的深度学习处理器和机器视觉系统的开发等，拥有丰富的AI加速器和图像信号处理器的设计落地经验。</span><br/><br/>\n        团队目前已经开发了基于车规级XAZU5EV器件的视觉雷达、视觉惯性里程计等产品。未来团队在 3D立体视觉、AI ISP、SLAM和多传感器融合计算等方向上制定了长期系统的规划，目标是面向传感器融合、感知、预测以及规划控制等计算任务提供高效能的计算平台。与最前沿的3D视觉感知算法团队紧密合作，提供业界领先的FPGA实现方案以及符合车规的图形图像处理IP和计算IP。'},{title:"软件团队",desc:'<span style="font-weight: 700; color: #202020;">软件团队深耕深度学习工程化十余年，拥有丰富的AI工程化和落地经验。核心团队在国内最早将GPU用于大规模深度学习训练，同时也是国内最早将CV算法移植部署在移动端并达到实时效果的先驱者。核心团队于业界率先提出基于数据流图的AI软件构建框架，伴随这套框架的不断演进，已在多个主流异构计算平台上完成规模化AI项目落地。</span><br/><br/>\n        当前团队涵盖自动驾驶全栈软件研发，在BSP、底层框架、中间件、应用等层面均有长期布局，目标是打造自动驾驶行业最安全、最稳定、最高效的软件系统，同时支持AI ISP、双目/多目立体视觉、高级别自动驾驶方案的可靠快速落地。'},{title:"硬件团队",desc:'<span style="font-weight: 700; color: #202020;">硬件团队来自头部自动驾驶方案和芯片公司，具备丰富的自动驾驶相关开发经验。自2015年始，便聚焦在人工智能视觉方面的软硬件协同，且图像和硬件加速能力完全实现自主知识产权。团队曾成功推出基于FPGA芯片的前感知平台产品系列，并畅销于国内外Robotaxi和国际Tier1公司。核心成员曾参与国内最早AI芯片开发、国内最早车规AI芯片开发以及自动驾驶图像模组和域控的开发。</span><br/><br/>\n        当前硬件团队负责平台性产品开发和自动驾驶方案硬件平台的自研等，包括加强鉴智自动驾驶前向感知核心能力的双目视觉雷达硬件产品和自动驾驶相关的图像ISP和一系列AI加速器芯片平台，如Orin、Qualcomm、地平线J芯片等高阶自动驾驶方案平台。'}]},talentConcept:{title:"人才理念",parts:[{title:"开放"},{title:"创新"},{title:"专注"},{title:"向上"}]},welfare:{title:"福利待遇",items:[{title:"丰厚年终奖,<br/>早期期权助力未来幸福生活"},{title:"全额社保，公积金与<br/>补充医疗保驾护航"},{title:"超长10天年假，产假与<br/>陪产假等休假福利"},{title:"花式水果零食下午茶"},{title:"各种社团和健身活动"},{title:"人体工学座椅兼顾效率和舒适"}]}},visualRadar:{banner:{text:"视觉雷达——<br>适用于高阶智能驾驶的<br>前向视觉感知",subText:'<span style="font-weight: 700; color: rgba(255,255,255,1);">PhiGent Heimdallr是一款面向高阶智能驾驶系统研发的四维视觉传感器。</span><br>  \n      稠密深度点云、像素级对齐的RGB数据、高帧率可支撑目标检测算法，更早地检测和识别各类动静态道路目标。<br>\n      配套的多类感知算法IP和一站式智驾打包方案，可进一步降低客户的应用周期和门槛。'},dallr:{parts:[{text:"2MP/8MP<br>分辨率"},{text:"60°/100°/120°<br>水平视场角"},{text:"30FPS<br>帧率"},{text:"RGB+Depth<br>同步输出"},{text:"可搭载鉴智自研<br>感知算法IP"},{text:"计算平台可由客户指定"}],content:[{label:"可搭载鉴智机器人自研的感知算法IP",text:"自研的感知算法IP主要指鉴智机器人基于PhiGent Heimdallr数据开发的全类型目标检测算法、车道线检测算法、交通标志识别、路面高程检测、路面类型识别等，客户可以结合应用需求选择对应的算法IP，对应的算力占用和适配周期需结合具体的项目沟通确定。"},{label:"计算平台可由客户指定",text:"客户指定计算平台时，鉴智机器人需将图像预处理、立体匹配、自标定、感知算法IP（如客户选择搭载）等软件模块部署在客户方的计算平台上，具体的算力占用、系统方案设计等需结合具体的项目沟通确定。"}]},cardItems:[{title:"像素级深度视觉传感器",text:"PhiGent Heimdallr每秒可输出超千万个深度点云，稠密的点云输出可以支撑目标检测算法，更精准地检测到远处行人、雪糕桶、三角警示牌等细小目标物体。",subText:{label:"像素级深度视觉传感器",text:"等同于匹配模块输入图像的分辨率，当前PhiGent Heimdallr所有规格的产品，深度高度分辨率均大于720P。"}},{title:"场景泛化性更优",text:'PhiGent Heimdallr搭载鉴智自研的深度学习立体匹配算法，在保留高精度测距能力的同时，<span class="stardot-label-right">应对弱纹理</span>、重复纹理的目标物（如纯色箱式货车、道路围栏等），也可精确匹配出深度点云，保证在交通事故现场和施工路段等极端交通场景中，感知系统仍具备鲁棒的检测能力。',subText:{label:"弱纹理",text:"被测目标物在视觉上和路面有明显颜色、纹理区别，不包括完全透明或镜面反射的物体。"}},{title:"纯视觉的全类型目标检测",text:"单一传感器可输出像素级对齐的深度点云和RGB图像，搭配深度学习识别和3D点云聚类目标检测算法，获得车辆、行人、路面标识、交通设施、道路遗撒碎石和纸箱在内的任意目标物的信息要素，提升前向视觉感知系统目标检测能力。"},{title:"在线自标定确保性能始终如一 ",text:"PhiGent Heimdallr标配在线自标定系统，确保产品在经受温度、震动、部件老化后，仍能维持原有的测距性能，降低系统失效风险和售后成本。"},{title:"车规级立体相机",text:"全栈正向设计开发，产品满足GB/T28046、GB/T21437、GB/T18655、ISO7637.3、GB/T 17626.4等常规标准要求外，针对车载环境特性增加了十余项特定的可靠性测试，确保产品可量产、稳定性强。"},{title:"全栈智驾方案+配套工具链加速量产落地",text:"鉴智机器人可提供包含PhiGent Heimdallr产品在内的全套智能驾驶方案和配套工具链，确保客户在保留系统定义主导权的同时，有效减少客户独自开发适配的周期和成本。",btnText:"了解PSD系统"}],productions:{title:"产品应用",parts:[{text:"智能驾驶前向感知"},{text:"半/全主动式智能悬架"},{text:"智驾功能降级冗余"},{text:"可通过性检测"}]},bottomVideo:{title:"PhiGent Heimdallr精彩瞬间",desc:"视觉雷达页面部分场景图使用DrivingStereo数据集，点云均为鉴智自有匹配算法运行效果。"}},autoDriving:{banner:{text:"自动驾驶解决方案",subText:'<span style="font-weight: 700;color: rgba(255,255,255,1);">以视觉3D理解为核心，基于软件2.0架构，打造端到端数据驱动的自动驾驶解决方案。</span><br>实现在多维空间中对自动驾驶车辆环境事无巨细的感知和理解，与行业伙伴一起推动<br>自动驾驶的创新和发展，重新定义未来出行。\n      '},solution:{subText:"采用以视觉为主兼容Radar、Lidar等传感器的前融合端到端优化方案，<br>提供从传感器层、感知层、规控应用层的全栈产品。",parts:[{text:"低算力需求"},{text:"强单车智能"},{text:"全栈算法能力"},{text:"持续可迭代"},{text:"体验可定制"}]},coreSolution:{title:"核心方案",subTitle:"视觉为主的灵活传感器配置",desc:"具有开放的软硬件框架，可以适配不同车载异构计算平台以及不同的传感器架构，<br>充分考虑客户对性价比和可靠性的双重需求，满足不同场景的功能体验需求。",details:[{title:"视觉感知",desc:"可依客户平台化需求进行配置定制，以满足不同自动驾驶等级的产品功能和不同场景覆盖的需求。"},{title:"毫米波雷达",desc:"根据实际方案配置，可减少毫米波雷达的数量。"},{title:"其他可兼容传感器",desc:""}]},projectBox:{title:"多传感器融合算法和量产工程能力",subTitle:"适配多传感器融合的丰富量产工程经验，基于高效的融合算法，交付高质量的智驾功能，<br>实现功能的多场景覆盖及体验提升。"},toolChain:{title:"完备的工具链支撑",tools:[{label:"数据闭环平台",content:"算法前置的数据采集系统加码数据闭环平台，显著提高有效数据密度，提升自动驾驶方案迭代效率。"},{label:"4D标注平台",content:"基于视觉雷达重建具有准确3D物体形状和颜色的全局点云，用于支撑4D标注，标注效率可成百倍提升，大幅缩短智能驾驶落地周期，降低成本。"},{label:"车载可视化HMI工具",content:"人性化的HMI设计可满足不同角色用户的需求。"}]},scene:{title:"丰富的场景",desc:"强大的感知算法和量产验证的工程化能力，可实现计算平台和传感器灵活组合的需求，以打造丰富的智驾场景。<br>\n      L4级自动驾驶全栈的软硬件结合能力，可根据不同的车型和场景规划提供降维的智驾解决方案，同时预留向高阶自动驾驶升级的能力。",cardList:[{title:"主动安全保障",desc:"量产验证的全速域主动安全系统，10万公里2次误触发，交付高质量城市安全体验。"},{title:"高速领航",desc:"支持自主上下匝道、最优车道选择、自动识别并调整限速、驾驶策略自适应调整。"},{title:"城市领航",desc:"支持复杂城市红绿灯路口、环岛等通行，城中村窄路通行，人机非混流场景行驶。"},{title:"全场景点对点",desc:"本地局部实时道路建图，结合导航地图，支持任意场景点到点定制，数据驱动持续优化。"}]},bottomVideo:{title:"自驾解决方案精彩瞬间"}},technology:{doubleCore:{title:"双核心驱动",parts:[{title:'构建基于<span style="color: #E50011">3D理解</span>的空间智能，<br/>实现机器与物理世界的精准交互',desc:"端到端数据驱动，实时三维环境重构建模，对三维空间事无巨细的理解，解决自动驾驶解决方案中视觉雷达、4D感知、实时建图等关键核心问题。"},{title:'<span style="color: #E50011">单车智能</span>覆盖全场景，<br/>应用模块灵活可定制',desc:"不依赖基础设施（V2X, HD-Map），以超强的单车感知能力和决策规划能力，实现跨场景精细丝滑的自动驾驶体验。灵活的模块化产品方案，可定制的用户驾乘及交互体验，助力软件服务付费订阅新模式。"}]},bevdet:{title:"BEVDet——<br>自动驾驶3D感知新范式",desc:'<span style="font-weight: 700; color: #202020;">在自动驾驶权威评测集nuScenes上，我们提出的纯视觉自动驾驶3D感知新范式BEVDet，<br>\n      获得纯视觉3D目标检测世界第一（2021）的成绩。</span><br>\n      构建眼脑协同，基于视觉雷达思想的自动驾驶感知框架，通过视觉为主传感系统，恢复整个空间的立体结构，并直接在<br>立体空间中进行的感知与理解。从BEVDet到BEVDet4D，鉴智机器人持续引领自动驾驶BEV感知新范式的发展。',chartParts:[{title:"BEVDet"},{title:"BEVDet4D"}],cardList:[{title:"高性能",desc:"BEVDet相比以Transformer进行image-to-bev投影的方式，拥有更优的泛化性能和更少的数据量要求，可大幅度降低对于数据量的需求。"},{title:"扩展性",desc:"BEVDet框架具有高度的扩展性，未来鉴智机器人将基于BEVDet进行扩展，进一步实现视觉雷达、4D感知、实时局部地图等纯自动驾驶关键核心模块，同时也给多传感器前融合提供了一个绝佳的新框架。"},{title:"实用性",desc:"BEVDet通过更低的算力需求达到同样或者更好的算法效果，可大幅度提高实际自动驾驶系统的算力利用效率。"}],part3D:{title:"BEVDet 3D感知技术指标",videos:[{title:"NuSense BEVDet 3D感知效果",desc:"BEVDet在nuSenses数据集上的效果"},{title:"6V周视感知 实车部署",desc:"基于BEVDet的高阶自动驾驶实车感知效果（2022/3）"}]}},control:{title:"具有世界领先水平的规划控制能力",desc:"传统规则与强化学习冗余并行，安全最优的环境模型建模能力，结合三维世界事无巨细的感知输入，<br>\n      实现精准预测，完成安全最优、通行轨迹最优的算法设计。<br>\n      自动化数据收集的影子系统完成基于BEV的端到端4D感知需求，打造具备双冗余、全场景泛化的规控系统。"},computeSolution:{title:"高性能自适应计算解决方案",desc:"在 3D立体视觉、AI ISP、SLAM和多传感器融合计算等方向上制定了长期系统的规划，<br>\n      目标面向传感器融合、感知、预测以及规划控制等计算任务提供高效能的计算平台。提供业界领先的<br/>FPGA实现方案，以及符合车规的图形图像处理IP和计算IP。"}},commen:{more:"了解更多",aboutus:"关于我们",showMore:"显示更多",noMore:"没有更多了～",backHome:"返回首页",navList:{home:"首页",coreTechnology:"核心技术",productions:"产品应用",aboutus:"关于我们",joinus:"加入我们",news:"新闻中心",autoDriving:"自动驾驶解决方案",visualRadar:"视觉雷达",companyInfo:"公司信息",history:"发展历程"}}},a=i(2536);const s=localStorage.getItem(a.E)||a.R.zh,r=s===a.R.zh?o:n;localStorage.setItem(a.E,s);var l=r},2536:function(e,t,i){i.d(t,{E:function(){return n},R:function(){return o}});const n="jzLanguage",o={en:"EN",zh:"ZH_CN"}}}]);